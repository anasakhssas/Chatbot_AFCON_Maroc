"""
Pipeline automatisÃ© pour l'application Streamlit
VÃ©rifie et exÃ©cute le pipeline ETL si nÃ©cessaire
"""

import logging
from pathlib import Path
from typing import Tuple, Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class AutoPipeline:
    """Gestionnaire de pipeline automatisÃ© pour l'application"""
    
    def __init__(self):
        """Initialiser le pipeline automatisÃ©"""
        from ..rag.config import RAGConfig
        self.config = RAGConfig
        
    def check_data_status(self) -> Dict[str, Any]:
        """
        VÃ©rifier l'Ã©tat des donnÃ©es
        
        Returns:
            Dictionnaire avec le statut de chaque Ã©tape
        """
        status = {
            'raw_data_exists': False,
            'transformed_data_exists': False,
            'vectorstore_exists': False,
            'needs_extraction': False,
            'needs_transformation': False,
            'needs_vectorization': False,
            'ready': False
        }
        
        # VÃ©rifier les donnÃ©es brutes
        raw_dir = self.config.DATA_DIR / "raw"
        if raw_dir.exists() and any(raw_dir.glob("*.json")):
            status['raw_data_exists'] = True
        
        # VÃ©rifier les donnÃ©es transformÃ©es
        if self.config.COMBINED_DATASET.exists():
            status['transformed_data_exists'] = True
        
        # VÃ©rifier le vectorstore
        if self.config.CHROMA_DB_DIR.exists():
            chroma_files = list(self.config.CHROMA_DB_DIR.glob("**/*"))
            if len(chroma_files) > 0:
                status['vectorstore_exists'] = True
        
        # DÃ©terminer les actions nÃ©cessaires
        if not status['raw_data_exists']:
            status['needs_extraction'] = True
        
        if not status['transformed_data_exists']:
            status['needs_transformation'] = True
        
        if not status['vectorstore_exists']:
            status['needs_vectorization'] = True
        
        # PrÃªt si tout existe
        status['ready'] = (
            status['raw_data_exists'] and 
            status['transformed_data_exists'] and 
            status['vectorstore_exists']
        )
        
        return status
    
    def run_extraction(self) -> bool:
        """
        ExÃ©cuter l'extraction des donnÃ©es
        
        Returns:
            True si rÃ©ussi, False sinon
        """
        logger.info("ğŸ“¥ Extraction des donnÃ©es...")
        try:
            from ..pipeline.demo_scraper import save_demo_data
            raw_data_path = save_demo_data()
            logger.info(f"âœ… Extraction rÃ©ussie: {raw_data_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'extraction: {e}")
            return False
    
    def run_transformation(self) -> bool:
        """
        ExÃ©cuter la transformation des donnÃ©es
        
        Returns:
            True si rÃ©ussi, False sinon
        """
        logger.info("ğŸ”„ Transformation des donnÃ©es pour RAG...")
        try:
            from ..pipeline.transform import DataTransformer
            transformer = DataTransformer()
            
            # Transformer tous les fichiers
            transformed_files = transformer.transform_all_files()
            
            if not transformed_files:
                logger.warning("âš ï¸ Aucun fichier transformÃ©")
                return False
            
            # CrÃ©er le dataset combinÃ©
            combined_path = transformer.create_combined_dataset()
            
            if combined_path:
                stats = transformer.get_statistics()
                logger.info(f"âœ… Transformation rÃ©ussie: {stats['total_documents']} documents")
                return True
            else:
                logger.error("âŒ Ã‰chec de crÃ©ation du dataset combinÃ©")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la transformation: {e}")
            return False
    
    def run_vectorization(self) -> bool:
        """
        ExÃ©cuter la vectorisation (crÃ©ation de ChromaDB)
        
        Returns:
            True si rÃ©ussi, False sinon
        """
        logger.info("ğŸ” Vectorisation et crÃ©ation de ChromaDB...")
        try:
            from ..rag.vectorizer import VectorizerCAN2025
            vectorizer = VectorizerCAN2025()
            vectorizer.create_vectorstore()
            logger.info("âœ… Vectorisation rÃ©ussie")
            return True
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la vectorisation: {e}")
            return False
    
    def ensure_ready(self, force_refresh: bool = False) -> Tuple[bool, str]:
        """
        S'assurer que toutes les donnÃ©es sont prÃªtes
        ExÃ©cute automatiquement les Ã©tapes manquantes
        
        Args:
            force_refresh: Si True, force la rÃ©gÃ©nÃ©ration complÃ¨te
        
        Returns:
            Tuple (succÃ¨s: bool, message: str)
        """
        logger.info("ğŸš€ VÃ©rification du pipeline de donnÃ©es...")
        
        # VÃ©rifier l'Ã©tat actuel
        status = self.check_data_status()
        
        if status['ready'] and not force_refresh:
            logger.info("âœ… Toutes les donnÃ©es sont prÃªtes")
            return True, "DonnÃ©es prÃªtes"
        
        steps_completed = []
        steps_failed = []
        
        # Ã‰tape 1: Extraction
        if status['needs_extraction'] or force_refresh:
            logger.info("ğŸ“¥ Ã‰tape 1/3: Extraction des donnÃ©es...")
            if self.run_extraction():
                steps_completed.append("Extraction")
            else:
                steps_failed.append("Extraction")
                return False, "Ã‰chec de l'extraction des donnÃ©es"
        else:
            logger.info("âœ“ DonnÃ©es brutes dÃ©jÃ  prÃ©sentes")
        
        # Ã‰tape 2: Transformation
        if status['needs_transformation'] or force_refresh:
            logger.info("ğŸ”„ Ã‰tape 2/3: Transformation des donnÃ©es...")
            if self.run_transformation():
                steps_completed.append("Transformation")
            else:
                steps_failed.append("Transformation")
                return False, "Ã‰chec de la transformation des donnÃ©es"
        else:
            logger.info("âœ“ DonnÃ©es transformÃ©es dÃ©jÃ  prÃ©sentes")
        
        # Ã‰tape 3: Vectorisation
        if status['needs_vectorization'] or force_refresh:
            logger.info("ğŸ” Ã‰tape 3/3: Vectorisation (ChromaDB)...")
            if self.run_vectorization():
                steps_completed.append("Vectorisation")
            else:
                steps_failed.append("Vectorisation")
                return False, "Ã‰chec de la vectorisation"
        else:
            logger.info("âœ“ ChromaDB dÃ©jÃ  crÃ©Ã©e")
        
        # RÃ©sumÃ©
        if steps_completed:
            message = f"Pipeline complÃ©tÃ©: {', '.join(steps_completed)}"
            logger.info(f"âœ… {message}")
        else:
            message = "Toutes les donnÃ©es Ã©taient dÃ©jÃ  prÃ©sentes"
            logger.info(f"âœ… {message}")
        
        if steps_failed:
            message = f"Ã‰checs: {', '.join(steps_failed)}"
            logger.error(f"âŒ {message}")
            return False, message
        
        return True, message
    
    def get_status_message(self) -> str:
        """
        Obtenir un message d'Ã©tat lisible
        
        Returns:
            Message dÃ©crivant l'Ã©tat du pipeline
        """
        status = self.check_data_status()
        
        if status['ready']:
            return "âœ… Pipeline prÃªt - Toutes les donnÃ©es sont chargÃ©es"
        
        messages = []
        if status['needs_extraction']:
            messages.append("âŒ Extraction requise")
        if status['needs_transformation']:
            messages.append("âŒ Transformation requise")
        if status['needs_vectorization']:
            messages.append("âŒ Vectorisation requise")
        
        return " | ".join(messages) if messages else "âš ï¸ Ã‰tat inconnu"
