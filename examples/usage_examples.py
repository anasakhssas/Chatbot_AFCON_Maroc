"""
Exemple d'utilisation des donnÃ©es transformÃ©es pour le RAG
"""
import json
from pathlib import Path
from collections import Counter

# Chemins
BASE_DIR = Path(__file__).resolve().parent.parent
DATASET_PATH = BASE_DIR / "data" / "transformed" / "combined_dataset.json"


def load_dataset():
    """Charger le dataset combinÃ©"""
    with open(DATASET_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)


def example_basic_stats():
    """Exemple 1: Statistiques de base"""
    print("=" * 70)
    print("ğŸ“Š EXEMPLE 1: Statistiques de Base")
    print("=" * 70)
    
    dataset = load_dataset()
    documents = dataset['documents']
    
    print(f"\nâœ… Total documents: {len(documents)}")
    print(f"ğŸ“… Date de crÃ©ation: {dataset['metadata']['creation_date']}")
    
    # Compter par catÃ©gorie
    categories = Counter(doc['metadata']['category'] for doc in documents)
    print("\nğŸ“‘ Par catÃ©gorie:")
    for cat, count in categories.items():
        print(f"  â€¢ {cat}: {count}")
    
    # Compter par source
    sources = Counter(doc['metadata']['source'] for doc in documents)
    print("\nğŸ“° Par source:")
    for src, count in sources.items():
        print(f"  â€¢ {src}: {count}")


def example_filter_by_category():
    """Exemple 2: Filtrer par catÃ©gorie"""
    print("\n" + "=" * 70)
    print("ğŸ” EXEMPLE 2: Filtrer par CatÃ©gorie")
    print("=" * 70)
    
    dataset = load_dataset()
    documents = dataset['documents']
    
    # Filtrer les rÃ©sultats de matchs
    match_results = [
        doc for doc in documents 
        if doc['metadata']['category'] == 'match_result'
    ]
    
    print(f"\nğŸ† RÃ©sultats de matchs trouvÃ©s: {len(match_results)}")
    print("\nPremiers 3 matchs:")
    for i, doc in enumerate(match_results[:3], 1):
        meta = doc['metadata']
        print(f"\n{i}. {meta['title']}")
        print(f"   ğŸ“… Date: {meta['date']}")
        print(f"   ğŸ”— Lien: {meta['link']}")


def example_search_by_team():
    """Exemple 3: Rechercher par Ã©quipe"""
    print("\n" + "=" * 70)
    print("ğŸ” EXEMPLE 3: Rechercher par Ã‰quipe")
    print("=" * 70)
    
    dataset = load_dataset()
    documents = dataset['documents']
    
    # Rechercher tous les articles sur le Maroc
    team = "Morocco"
    morocco_articles = [
        doc for doc in documents 
        if team in doc['text'] or team in str(doc['metadata']['keywords'])
    ]
    
    print(f"\nğŸ‡²ğŸ‡¦ Articles mentionnant '{team}': {len(morocco_articles)}")
    print("\nTitres:")
    for i, doc in enumerate(morocco_articles, 1):
        print(f"{i}. {doc['metadata']['title']}")


def example_search_by_player():
    """Exemple 4: Rechercher par joueur"""
    print("\n" + "=" * 70)
    print("ğŸ” EXEMPLE 4: Rechercher par Joueur")
    print("=" * 70)
    
    dataset = load_dataset()
    documents = dataset['documents']
    
    # Rechercher les articles mentionnant Salah
    player = "Salah"
    player_articles = [
        doc for doc in documents 
        if player in doc['text']
    ]
    
    print(f"\nâš½ Articles mentionnant '{player}': {len(player_articles)}")
    for doc in player_articles:
        meta = doc['metadata']
        print(f"\nğŸ“° {meta['title']}")
        print(f"   ğŸ“… {meta['date']}")
        # Extraire le contexte autour du nom du joueur
        text = doc['text']
        idx = text.find(player)
        if idx != -1:
            context = text[max(0, idx-50):min(len(text), idx+100)]
            print(f"   ğŸ“ Contexte: ...{context}...")


def example_get_latest_news():
    """Exemple 5: Obtenir les derniÃ¨res news"""
    print("\n" + "=" * 70)
    print("ğŸ“° EXEMPLE 5: DerniÃ¨res ActualitÃ©s")
    print("=" * 70)
    
    dataset = load_dataset()
    documents = dataset['documents']
    
    # Trier par date
    sorted_docs = sorted(
        documents, 
        key=lambda x: x['metadata']['date'], 
        reverse=True
    )
    
    print("\nğŸ†• Les 5 derniÃ¨res actualitÃ©s:")
    for i, doc in enumerate(sorted_docs[:5], 1):
        meta = doc['metadata']
        print(f"\n{i}. {meta['title']}")
        print(f"   ğŸ“… {meta['date']}")
        print(f"   ğŸ“‘ CatÃ©gorie: {meta['category']}")


def example_prepare_for_rag():
    """Exemple 6: PrÃ©parer les donnÃ©es pour le RAG"""
    print("\n" + "=" * 70)
    print("ğŸ¤– EXEMPLE 6: Format pour le RAG")
    print("=" * 70)
    
    dataset = load_dataset()
    documents = dataset['documents']
    
    # Format pour LangChain/LlamaIndex
    rag_documents = []
    for doc in documents[:3]:  # Prendre les 3 premiers comme exemple
        rag_doc = {
            "page_content": doc['text'],  # Le texte pour la vectorisation
            "metadata": doc['metadata']    # MÃ©tadonnÃ©es pour le filtrage
        }
        rag_documents.append(rag_doc)
    
    print("\nğŸ“¦ Format prÃªt pour LangChain/LlamaIndex:")
    print(f"   â€¢ Nombre de documents: {len(rag_documents)}")
    print(f"   â€¢ Structure: page_content + metadata")
    print("\nğŸ“ Exemple de document:")
    print(json.dumps(rag_documents[0], indent=2, ensure_ascii=False)[:500] + "...")


def main():
    """ExÃ©cuter tous les exemples"""
    print("\n" + "ğŸ†" * 35)
    print("     EXEMPLES D'UTILISATION - DONNÃ‰ES CAN 2025")
    print("ğŸ†" * 35 + "\n")
    
    if not DATASET_PATH.exists():
        print("âŒ Dataset non trouvÃ©. ExÃ©cutez d'abord le pipeline:")
        print("   python -m src.pipeline.pipeline")
        return
    
    # ExÃ©cuter les exemples
    example_basic_stats()
    example_filter_by_category()
    example_search_by_team()
    example_search_by_player()
    example_get_latest_news()
    example_prepare_for_rag()
    
    print("\n" + "=" * 70)
    print("âœ… Tous les exemples terminÃ©s!")
    print("=" * 70)
    print("\nğŸ’¡ Ces exemples montrent comment:")
    print("   â€¢ Charger et explorer le dataset")
    print("   â€¢ Filtrer par catÃ©gorie, Ã©quipe, joueur")
    print("   â€¢ PrÃ©parer les donnÃ©es pour le RAG")
    print("\nğŸš€ Prochaine Ã©tape: CrÃ©er les embeddings et ChromaDB")


if __name__ == "__main__":
    main()
